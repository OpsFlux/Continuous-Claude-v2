#!/usr/bin/env python3
"""
æ‰¹é‡ç¿»è¯‘æ–‡æ¡£è„šæœ¬ (Bulk Document Translation Script)

å°†æŒ‡å®šç›®å½•ä¸‹çš„æ–‡æ¡£æ‰¹é‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶æ›¿æ¢åŸæ–‡ä»¶ã€‚
é»˜è®¤ä½¿ç”¨ MyMemory å…è´¹ç¿»è¯‘æ¥å£ï¼ˆå•æ¬¡è¯·æ±‚æ–‡æœ¬é•¿åº¦ä¸Šé™ 500 å­—ç¬¦ï¼‰ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨åˆ†æ®µä¸é‡è¯•ã€‚

ç›®æ ‡ï¼š
- ä¿ç•™ Markdown / çº¯æ–‡æœ¬çš„ç»“æ„ä¸æ ¼å¼
- ä¸ç¿»è¯‘ä»£ç å—ï¼ˆ``` fenced code æˆ–ç¼©è¿›ä»£ç ï¼‰
- ä¸ç¿»è¯‘ YAML frontmatterï¼ˆMarkdown é¡¶éƒ¨ --- ... ---ï¼‰
- å°½é‡ä¿ç•™ URL / é‚®ç®± / è·¯å¾„ / è¡Œå†…ä»£ç ï¼ˆ`...`ï¼‰

ä½¿ç”¨æ–¹æ³• (Usage):
    python3 scripts/translate_documents.py --dry-run
    python3 scripts/translate_documents.py --yes

å¯é€‰ï¼šLibreTranslateï¼ˆå¦‚ä½ æœ‰ API keyï¼‰
    export LIBRETRANSLATE_URL='https://your-instance/translate'
    export LIBRETRANSLATE_API_KEY='...'
    python3 scripts/translate_documents.py --provider libretranslate --yes
"""

from __future__ import annotations

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import asyncio
import aiohttp
import html
import re

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.md', '.txt', '.rst', '.adoc'}

# éœ€è¦æ’é™¤çš„ç›®å½•
EXCLUDED_DIRS = {
    '.git', 'node_modules', 'venv', '.venv', '__pycache__',
    '.pytest_cache', 'dist', 'build', '.mypy_cache', '.tox'
}


def find_documents(root_dir: Path, extensions: set = None) -> List[Path]:
    """
    é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
    Recursively find all document files
    """
    if extensions is None:
        extensions = SUPPORTED_EXTENSIONS

    documents = []
    for file_path in root_dir.rglob('*'):
        # è·³è¿‡æ’é™¤çš„ç›®å½•
        if any(excluded in file_path.parts for excluded in EXCLUDED_DIRS):
            continue

        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix.lower() in extensions and file_path.is_file():
            documents.append(file_path)

    return sorted(documents)


_CJK_RE = re.compile(r"[\u4e00-\u9fff]")
_URL_RE = re.compile(r"https?://[^\s)\]>}]+")
_EMAIL_RE = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
_INLINE_CODE_RE = re.compile(r"`([^`]+)`")
_MD_HEADING_RE = re.compile(r"^(#{1,6})(\s+)(.+)$")
_MD_LIST_RE = re.compile(r"^(\s*)([-*+]|(\d+\.))(\s+)(.+)$")
_MD_QUOTE_RE = re.compile(r"^(\s*(?:>\s*)+)(.+)$")
_MD_INLINE_LINK_RE = re.compile(r"\[([^\]\n]+)\]\(([^)\n]+)\)")
_PRESERVE_SPAN_RE = re.compile(
    r"(`[^`]+`|https?://[^\s)\]>}]+|[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}|(?<!\w)(?:\./|\.\./|/)[A-Za-z0-9._~/-]+)"
)


def _count_latin_letters(text: str) -> int:
    return sum(1 for ch in text if ("A" <= ch <= "Z") or ("a" <= ch <= "z"))


def _count_cjk(text: str) -> int:
    return len(_CJK_RE.findall(text))


def _should_translate_snippet(text: str) -> bool:
    if not text.strip():
        return False
    latin = _count_latin_letters(text)
    if latin < 3:
        return False
    cjk = _count_cjk(text)
    # å·²ç»æ˜¯æ˜æ˜¾ä¸­æ–‡ä¸ºä¸»æ—¶ï¼Œé¿å…â€œä¸­æ–‡->ä¸­æ–‡â€å¯¼è‡´æªè¾æ¼‚ç§»
    if cjk > 0 and cjk > latin * 2:
        return False
    return True


def _split_yaml_frontmatter(lines: List[str]) -> Tuple[List[str], List[str]]:
    if not lines or lines[0].strip() != "---":
        return [], lines
    for i in range(1, min(len(lines), 200)):
        if lines[i].strip() == "---":
            return lines[: i + 1], lines[i + 1 :]
    return [], lines


async def _translate_plain_text(translator: Translator, text: str, max_chars: int) -> str:
    """
    ç¿»è¯‘çº¯æ–‡æœ¬ç‰‡æ®µï¼Œä¿ç•™è¡Œå†…ä»£ç /URL/é‚®ç®±/è·¯å¾„ç­‰ä¸å¯ç¿»è¯‘ç‰‡æ®µã€‚
    """
    if not text:
        return text

    parts: List[str] = []
    pos = 0
    for m in _PRESERVE_SPAN_RE.finditer(text):
        pre = text[pos : m.start()]
        if pre:
            parts.append(pre)
        parts.append(m.group(0))
        pos = m.end()
    tail = text[pos:]
    if tail:
        parts.append(tail)

    out: List[str] = []
    for part in parts:
        if not part:
            continue
        if _PRESERVE_SPAN_RE.fullmatch(part):
            out.append(part)
            continue
        if not _should_translate_snippet(part):
            out.append(part)
            continue
        for chunk in _chunk_text(part, max_chars=max_chars):
            if _should_translate_snippet(chunk):
                out.append(await translator.translate(chunk))
            else:
                out.append(chunk)
    return "".join(out)


async def _translate_markdown_inline(translator: Translator, text: str, max_chars: int) -> str:
    """
    é’ˆå¯¹ Markdown è¡Œå†…é“¾æ¥çš„ç¿»è¯‘ï¼šç¿»è¯‘ [label]ï¼Œä¿ç•™ (dest) åŸæ ·ã€‚
    """
    if not text:
        return text
    out: List[str] = []
    pos = 0
    for m in _MD_INLINE_LINK_RE.finditer(text):
        before = text[pos : m.start()]
        if before:
            out.append(await _translate_plain_text(translator, before, max_chars=max_chars))
        label = m.group(1)
        dest = m.group(2)
        translated_label = await _translate_plain_text(translator, label, max_chars=max_chars)
        out.append(f"[{translated_label}]({dest})")
        pos = m.end()
    tail = text[pos:]
    if tail:
        out.append(await _translate_plain_text(translator, tail, max_chars=max_chars))
    return "".join(out)


def _chunk_text(text: str, max_chars: int) -> List[str]:
    """
    å°†æ–‡æœ¬åˆ†æˆ <= max_chars çš„ç‰‡æ®µï¼Œå°½é‡åœ¨ç©ºç™½å¤„åˆ†å‰²ã€‚
    """
    if len(text) <= max_chars:
        return [text]

    parts: List[str] = []
    current = ""
    for piece in re.split(r"(\s+)", text):
        if not piece:
            continue
        if len(current) + len(piece) > max_chars and current.strip():
            parts.append(current)
            current = piece
        else:
            current += piece
    if current:
        parts.append(current)
    return parts


class Translator:
    async def translate(self, text: str) -> str:
        raise NotImplementedError


class MyMemoryTranslator(Translator):
    """
    å…è´¹æ¥å£ï¼ˆ500 chars é™åˆ¶ï¼‰ï¼šhttps://api.mymemory.translated.net/
    """

    def __init__(self, session: aiohttp.ClientSession, *, source: str, target: str) -> None:
        self._session = session
        self._source = source
        self._target = target
        self._cache: Dict[str, str] = {}

    async def translate(self, text: str) -> str:
        if text in self._cache:
            return self._cache[text]

        params = {"q": text, "langpair": f"{self._source}|{self._target}"}

        # è½»å¾®èŠ‚æµï¼Œé¿å…è¢«é™é€Ÿ
        await asyncio.sleep(0.1)

        for attempt in range(6):
            try:
                async with self._session.get(
                    "https://api.mymemory.translated.net/get",
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=30),
                ) as resp:
                    data = await resp.json()
                    translated = (
                        data.get("responseData", {}).get("translatedText")
                        if isinstance(data, dict)
                        else None
                    )
                    if not translated:
                        raise RuntimeError(f"unexpected response: {data}")
                    if "QUERY LENGTH LIMIT EXCEEDED" in translated:
                        raise ValueError("query length limit exceeded")
                    if "MYMEMORY WARNING" in translated or "AVAILABLE FREE TRANSLATIONS" in translated:
                        raise RuntimeError("mymemory quota exhausted")

                    translated = html.unescape(translated)
                    self._cache[text] = translated
                    return translated
            except ValueError:
                raise
            except Exception:
                await asyncio.sleep(0.5 * (2**attempt))

        return text


class LibreTranslateTranslator(Translator):
    def __init__(self, session: aiohttp.ClientSession, *, api_url: str, api_key: str, source: str, target: str):
        self._session = session
        self._api_url = api_url
        self._api_key = api_key
        self._source = source
        self._target = target
        self._cache: Dict[str, str] = {}

    async def translate(self, text: str) -> str:
        if text in self._cache:
            return self._cache[text]

        payload = {"q": text, "source": self._source, "target": self._target, "format": "text"}
        headers = {"Content-Type": "application/json"}
        if self._api_key:
            headers["Authorization"] = f"Bearer {self._api_key}"

        for attempt in range(6):
            try:
                async with self._session.post(
                    self._api_url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=30)
                ) as resp:
                    data = await resp.json()
                    translated = data.get("translatedText")
                    if not translated:
                        raise RuntimeError(f"unexpected response: {data}")
                    self._cache[text] = translated
                    return translated
            except Exception:
                await asyncio.sleep(0.5 * (2**attempt))

        return text


class ArgosTranslator(Translator):
    """
    Argos Translateï¼šç¦»çº¿ç¿»è¯‘ï¼ˆéœ€è¦é¢„å…ˆå®‰è£… en->zh è¯­è¨€åŒ…ï¼‰ã€‚
    """

    def __init__(self, *, source: str, target: str) -> None:
        import argostranslate.translate  # type: ignore

        self._source = source
        self._target = target
        self._translate_fn = argostranslate.translate.translate
        self._cache: Dict[str, str] = {}

    async def translate(self, text: str) -> str:
        if text in self._cache:
            return self._cache[text]
        translated = await asyncio.to_thread(self._translate_fn, text, self._source, self._target)
        self._cache[text] = translated
        return translated


async def _translate_snippet(translator: Translator, snippet: str, max_chars: int) -> str:
    if not _should_translate_snippet(snippet):
        return snippet
    return await _translate_markdown_inline(translator, snippet, max_chars=max_chars)


def _is_markdown_table_separator(line: str) -> bool:
    stripped = line.strip()
    if "|" not in stripped:
        return False
    # e.g. | --- | :---: | ---: |
    return all(ch in "|:- " for ch in stripped)


def _github_slugify(heading: str, existing: Dict[str, int]) -> str:
    """
    è¿‘ä¼¼ GitHub Markdown çš„ heading slugï¼ˆç”¨äºç¨³å®š idï¼‰ã€‚
    åªå¤„ç†å¸¸è§ ASCII headingï¼šå°å†™ã€å»æ ‡ç‚¹ã€ç©ºç™½->-ã€é‡å¤è¿½åŠ  -nã€‚
    """
    text = heading.strip().lower()
    # remove trailing hashes like "Title ###"
    text = re.sub(r"\s+#+\s*$", "", text)
    # keep alnum, space, hyphen, underscore
    text = re.sub(r"[^a-z0-9 _-]+", "", text)
    text = text.replace(" ", "-")
    text = re.sub(r"-{2,}", "-", text).strip("-")
    if not text:
        text = "section"
    count = existing.get(text, 0)
    existing[text] = count + 1
    return text if count == 0 else f"{text}-{count}"


def _extract_markdown_heading_ids(content: str) -> List[str]:
    lines = content.splitlines()
    frontmatter, rest = _split_yaml_frontmatter(lines)

    ids: List[str] = []
    in_fence = False
    fence_marker: Optional[str] = None
    existing: Dict[str, int] = {}

    for line in rest:
        stripped = line.strip()
        if stripped.startswith("```") or stripped.startswith("~~~"):
            marker = stripped[:3]
            if not in_fence:
                in_fence = True
                fence_marker = marker
            else:
                if fence_marker == marker:
                    in_fence = False
                    fence_marker = None
            continue
        if in_fence:
            continue

        m = _MD_HEADING_RE.match(line)
        if not m:
            continue
        heading_text = m.group(3)
        ids.append(_github_slugify(heading_text, existing))

    return ids


async def translate_document_content(
    translator: Translator,
    content: str,
    file_path: Path,
    *,
    chunk_limit: int,
    heading_ids: Optional[List[str]] = None,
) -> str:
    """
    é¢å‘ Markdown çš„è½»é‡ç»“æ„åŒ–ç¿»è¯‘ï¼ˆå¯¹ .txt/.rst/.adoc ä¹Ÿå¯ç”¨ï¼‰ã€‚
    """
    lines = content.splitlines()

    frontmatter, rest = _split_yaml_frontmatter(lines) if file_path.suffix.lower() == ".md" else ([], lines)
    out: List[str] = []
    out.extend(frontmatter)

    in_fence = False
    fence_marker: Optional[str] = None

    paragraph_buf: List[str] = []

    async def flush_paragraph() -> None:
        nonlocal paragraph_buf
        if not paragraph_buf:
            return
        block = "\n".join(paragraph_buf)
        translated = await _translate_snippet(translator, block, max_chars=chunk_limit)
        out.extend(translated.splitlines())
        paragraph_buf = []

    for line in rest:
        stripped = line.strip()

        # fenced code
        if stripped.startswith("```") or stripped.startswith("~~~"):
            await flush_paragraph()
            marker = stripped[:3]
            if not in_fence:
                in_fence = True
                fence_marker = marker
            else:
                if fence_marker == marker:
                    in_fence = False
                    fence_marker = None
            out.append(line)
            continue

        if in_fence:
            out.append(line)
            continue

        # indented code (markdown / rst common)
        if line.startswith("\t") or line.startswith("    "):
            await flush_paragraph()
            out.append(line)
            continue

        # blank line ends paragraph
        if not stripped:
            await flush_paragraph()
            out.append(line)
            continue

        # markdown specific single-line structures
        m = _MD_HEADING_RE.match(line)
        if m:
            await flush_paragraph()
            if heading_ids is not None and file_path.suffix.lower() == ".md" and heading_ids:
                anchor_id = heading_ids.pop(0)
                out.append(f'<a id="{anchor_id}"></a>')
            prefix = f"{m.group(1)}{m.group(2)}"
            translated = await _translate_snippet(translator, m.group(3), max_chars=chunk_limit)
            out.append(prefix + translated)
            continue

        m = _MD_QUOTE_RE.match(line)
        if m:
            await flush_paragraph()
            prefix = m.group(1)
            translated = await _translate_snippet(translator, m.group(2), max_chars=chunk_limit)
            out.append(prefix + translated)
            continue

        m = _MD_LIST_RE.match(line)
        if m:
            await flush_paragraph()
            indent, bullet, _, space, rest_text = m.group(1), m.group(2), m.group(3), m.group(4), m.group(5)
            checkbox_match = re.match(r"^(\[[ xX]\]\s+)(.+)$", rest_text)
            if checkbox_match:
                checkbox = checkbox_match.group(1)
                item_text = checkbox_match.group(2)
                translated = await _translate_snippet(translator, item_text, max_chars=chunk_limit)
                out.append(f"{indent}{bullet}{space}{checkbox}{translated}")
            else:
                translated = await _translate_snippet(translator, rest_text, max_chars=chunk_limit)
                out.append(f"{indent}{bullet}{space}{translated}")
            continue

        if "|" in line and not _is_markdown_table_separator(line) and line.count("|") >= 2:
            await flush_paragraph()
            # å°½é‡ä¿ç•™é¦–å°¾ pipe
            leading_pipe = line.lstrip().startswith("|")
            trailing_pipe = line.rstrip().endswith("|")
            raw_cells = line.split("|")
            # split keeps leading/trailing empty cells
            translated_cells: List[str] = []
            for cell in raw_cells:
                cell_stripped = cell.strip()
                if not cell_stripped:
                    translated_cells.append(cell)
                    continue
                translated_cell = await _translate_snippet(translator, cell_stripped, max_chars=chunk_limit)
                # keep original surrounding spaces roughly
                left_ws = cell[: len(cell) - len(cell.lstrip(" "))]
                right_ws = cell[len(cell.rstrip(" ")) :]
                translated_cells.append(f"{left_ws}{translated_cell}{right_ws}")
            rebuilt = "|".join(translated_cells)
            # keep pipe style stable
            if leading_pipe and not rebuilt.lstrip().startswith("|"):
                rebuilt = "|" + rebuilt
            if trailing_pipe and not rebuilt.rstrip().endswith("|"):
                rebuilt = rebuilt + "|"
            out.append(rebuilt)
            continue

        # default: accumulate into paragraph (keeps original wrapping)
        paragraph_buf.append(line)

    await flush_paragraph()

    # Preserve trailing newline if present
    result = "\n".join(out)
    if content.endswith("\n"):
        result += "\n"
    return result


async def translate_document(
    file_path: Path,
    translator: Translator,
    dry_run: bool = False
) -> Tuple[bool, str]:
    """
    ç¿»è¯‘å•ä¸ªæ–‡æ¡£æ–‡ä»¶
    Translate a single document file
    """
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        if dry_run:
            return True, f"[DRY-RUN] {file_path}"

        heading_ids = (
            _extract_markdown_heading_ids(original_content)
            if file_path.suffix.lower() == ".md"
            else None
        )
        translated_content = await translate_document_content(
            translator, original_content, file_path, chunk_limit=450, heading_ids=heading_ids
        )

        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(translated_content)

        return True, f"âœ“ {file_path}"

    except Exception as e:
        return False, f"âœ— {file_path}: {str(e)}"


async def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡ç¿»è¯‘æ–‡æ¡£ä¸ºä¸­æ–‡ (Bulk translate documents to Chinese)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ç¿»è¯‘æ–‡ä»¶ (Preview mode, do not actually translate files)'
    )
    parser.add_argument(
        '--yes',
        action='store_true',
        help='è·³è¿‡ç¡®è®¤å¹¶ç›´æ¥è¦†ç›–æ–‡ä»¶ (Skip confirmation and overwrite files)'
    )
    parser.add_argument(
        '--provider',
        choices=['argos', 'mymemory', 'libretranslate'],
        default='argos',
        help='ç¿»è¯‘æä¾›æ–¹ (Translation provider)'
    )
    parser.add_argument(
        '--api-url',
        default=os.getenv('LIBRETRANSLATE_URL', 'https://libretranslate.com/translate'),
        help='LibreTranslate APIç«¯ç‚¹ï¼ˆprovider=libretranslateæ—¶ä½¿ç”¨ï¼‰'
    )
    parser.add_argument(
        '--api-key',
        default=os.getenv('LIBRETRANSLATE_API_KEY', ''),
        help='LibreTranslate APIå¯†é’¥ï¼ˆprovider=libretranslateæ—¶ä½¿ç”¨ï¼‰'
    )
    parser.add_argument(
        '--dir',
        default='.',
        help='è¦ç¿»è¯‘çš„æ ¹ç›®å½• (Root directory to translate)'
    )
    parser.add_argument(
        '--extensions',
        default='md,txt,rst,adoc',
        help='è¦ç¿»è¯‘çš„æ–‡ä»¶æ‰©å±•åï¼Œé€—å·åˆ†éš” (File extensions to translate, comma-separated)'
    )
    parser.add_argument(
        '--source-lang',
        default='en',
        help='æºè¯­è¨€ï¼ˆé»˜è®¤ enï¼›MyMemory ä¸æ”¯æŒ autoï¼‰'
    )
    parser.add_argument(
        '--target-lang',
        default='zh',
        help='ç›®æ ‡è¯­è¨€ï¼ˆé»˜è®¤ zhï¼›MyMemory å»ºè®®ä½¿ç”¨ zh-CNï¼‰'
    )

    args = parser.parse_args()

    # è§£ææ‰©å±•å
    extensions = set(f'.{ext.strip()}' for ext in args.extensions.split(','))

    # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£
    root_dir = Path(args.dir)
    print(f"ğŸ” æ­£åœ¨æ‰«ææ–‡æ¡£... (Scanning documents...)")
    documents = find_documents(root_dir, extensions)

    if not documents:
        print("âŒ æœªæ‰¾åˆ°æ–‡æ¡£æ–‡ä»¶ (No document files found)")
        return

    print(f"ğŸ“„ æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£æ–‡ä»¶ (Found {len(documents)} document files)")
    print()

    if args.dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - ä»¥ä¸‹æ–‡ä»¶å°†è¢«ç¿»è¯‘ (Preview mode - following files will be translated):")
        for doc in documents:
            print(f"  - {doc}")
        print()
        print("ğŸ’¡ æç¤º: ç§»é™¤ --dry-run å‚æ•°ä»¥æ‰§è¡Œå®é™…ç¿»è¯‘ (Tip: Remove --dry-run to execute actual translation)")
        return

    # ç¡®è®¤æ“ä½œ
    print(f"âš ï¸  è­¦å‘Š: å³å°†ç¿»è¯‘å¹¶æ›¿æ¢ {len(documents)} ä¸ªæ–‡ä»¶ (Warning: About to translate and replace {len(documents)} files)")
    if args.provider == 'libretranslate':
        print(f"ğŸŒ LibreTranslateç«¯ç‚¹: {args.api_url}")
    elif args.provider == 'mymemory':
        print("ğŸŒ Provider: MyMemory (free, 500 chars/request limit)")
    else:
        print("ğŸŒ Provider: Argos Translate (offline)")
    if not args.yes:
        response = input("æ˜¯å¦ç»§ç»­? (Continue?) [y/N]: ")
        if response.lower() != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ (Operation cancelled)")
            return

    # æ‰§è¡Œç¿»è¯‘
    print(f"\nğŸŒ å¼€å§‹ç¿»è¯‘... (Starting translation...)\n")

    success_count = 0
    fail_count = 0

    if args.provider == 'argos':
        try:
            import argostranslate.translate  # type: ignore  # noqa: F401
        except Exception:
            print("âŒ æœªå®‰è£… argostranslateï¼Œæ— æ³•ä½¿ç”¨ç¦»çº¿ç¿»è¯‘ (provider=argos)ã€‚")
            print("   å»ºè®®å…ˆåˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ï¼š")
            print("   python3 -m venv .venv")
            print("   .venv/bin/python -m pip install argostranslate aiohttp")
            sys.exit(1)
        translator = ArgosTranslator(source=args.source_lang, target=args.target_lang)
        for i, doc in enumerate(documents, 1):
            print(f"[{i}/{len(documents)}] ", end='')
            success, message = await translate_document(doc, translator, args.dry_run)
            if success:
                success_count += 1
            else:
                fail_count += 1
            print(message)
        # æ€»ç»“
        print(f"\n{'='*60}")
        print(f"âœ“ ç¿»è¯‘å®Œæˆ (Translation complete)")
        print(f"  æˆåŠŸ (Success): {success_count}")
        print(f"  å¤±è´¥ (Failed): {fail_count}")
        print(f"  æ€»è®¡ (Total): {len(documents)}")
        print(f"{'='*60}")
        return

    async with aiohttp.ClientSession() as session:
        if args.provider == 'libretranslate':
            translator = LibreTranslateTranslator(
                session,
                api_url=args.api_url,
                api_key=args.api_key,
                source=args.source_lang,
                target=args.target_lang,
            )
        else:
            target = args.target_lang
            if target == "zh":
                target = "zh-CN"
            translator = MyMemoryTranslator(session, source=args.source_lang, target=target)

        for i, doc in enumerate(documents, 1):
            print(f"[{i}/{len(documents)}] ", end='')
            success, message = await translate_document(doc, translator, args.dry_run)
            if success:
                success_count += 1
            else:
                fail_count += 1
            print(message)

    # æ€»ç»“
    print(f"\n{'='*60}")
    print(f"âœ“ ç¿»è¯‘å®Œæˆ (Translation complete)")
    print(f"  æˆåŠŸ (Success): {success_count}")
    print(f"  å¤±è´¥ (Failed): {fail_count}")
    print(f"  æ€»è®¡ (Total): {len(documents)}")
    print(f"{'='*60}")


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­ (Operation interrupted by user)")
        sys.exit(1)
