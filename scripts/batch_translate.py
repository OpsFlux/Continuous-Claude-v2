#!/usr/bin/env python3
"""
æ–‡æ¡£æ‰¹é‡ç¿»è¯‘è„šæœ¬ - ä½¿ç”¨å†…ç½®ç¿»è¯‘
"""

import os
import sys
from pathlib import Path
from typing import Dict, List
import re

# ç®€å•çš„å¸¸ç”¨æœ¯è¯­æ˜ å°„è¡¨
TERM_MAPPING: Dict[str, str] = {
    # é¡¹ç›®ç›¸å…³
    "Continuous Claude": "Continuous Claudeï¼ˆæŒç»­Claudeï¼‰",
    "Claude Code": "Claude Code",

    # æŠ€æœ¯æœ¯è¯­
    "MCP": "MCPï¼ˆModel Context Protocolï¼‰",
    "MCP server": "MCPæœåŠ¡å™¨",
    "MCP tools": "MCPå·¥å…·",
    "hook": "hookï¼ˆé’©å­ï¼‰",
    "hooks": "hooksï¼ˆé’©å­ï¼‰",
    "skill": "skillï¼ˆæŠ€èƒ½ï¼‰",
    "skills": "skillsï¼ˆæŠ€èƒ½ï¼‰",
    "agent": "agentï¼ˆä»£ç†ï¼‰",
    "agents": "agentsï¼ˆä»£ç†ï¼‰",
    "ledger": "ledgerï¼ˆè´¦æœ¬ï¼‰",
    "handoff": "handoffï¼ˆäº¤æ¥ï¼‰",
    "handoffs": "handoffsï¼ˆäº¤æ¥ï¼‰",
    "continuity": "continuityï¼ˆè¿ç»­æ€§ï¼‰",
    "TDD": "TDDï¼ˆæµ‹è¯•é©±åŠ¨å¼€å‘ï¼‰",

    # å…¶ä»–æœ¯è¯­
    "token": "tokenï¼ˆä»¤ç‰Œï¼‰",
    "tokens": "tokensï¼ˆä»¤ç‰Œï¼‰",
    "repository": "repositoryï¼ˆä»“åº“ï¼‰",
    "repo": "repoï¼ˆä»“åº“ï¼‰",
    "artifact": "artifactï¼ˆåˆ¶å“ï¼‰",
    "artifacts": "artifactsï¼ˆåˆ¶å“ï¼‰",
    "trace": "traceï¼ˆè¿½è¸ªï¼‰",
    "traces": "tracesï¼ˆè¿½è¸ªï¼‰",
    "span": "spanï¼ˆè·¨åº¦ï¼‰",
    "session": "sessionï¼ˆä¼šè¯ï¼‰",
    "sessions": "sessionsï¼ˆä¼šè¯ï¼‰",
    "workflow": "workflowï¼ˆå·¥ä½œæµï¼‰",
    "scripts": "scriptsï¼ˆè„šæœ¬ï¼‰",
}


def translate_line(line: str, in_code_block: bool) -> str:
    """
    ç¿»è¯‘å•è¡Œæ–‡æœ¬ï¼Œä¿ç•™ä»£ç å—å’Œç‰¹æ®Šæ ¼å¼
    """
    # å¦‚æœåœ¨ä»£ç å—ä¸­ï¼Œä¸ç¿»è¯‘
    if in_code_block:
        return line

    # ç©ºè¡Œç›´æ¥è¿”å›
    if not line.strip():
        return line

    # Markdownæ ‡é¢˜
    if line.startswith('#'):
        return translate_markdown_heading(line)

    # åˆ—è¡¨é¡¹
    if line.strip().startswith(('-', '*', '+')) and not line.strip().startswith('```'):
        return translate_list_item(line)

    # ä»£ç å—æ ‡è®°
    if line.strip().startswith('```'):
        return line

    # æ™®é€šæ–‡æœ¬
    return translate_simple_text(line)


def translate_markdown_heading(line: str) -> str:
    """ç¿»è¯‘Markdownæ ‡é¢˜"""
    match = re.match(r'^(#+)\s+(.+)$', line)
    if not match:
        return line

    level = match.group(1)
    text = match.group(2)
    translated = translate_text(text)

    return f"{level} {translated}"


def translate_list_item(line: str) -> str:
    """ç¿»è¯‘åˆ—è¡¨é¡¹"""
    match = re.match(r'^(\s*)([-*+])\s+(.+)$', line)
    if not match:
        return line

    indent = match.group(1)
    bullet = match.group(2)
    text = match.group(3)
    translated = translate_text(text)

    return f"{indent}{bullet} {translated}"


def translate_text(text: str) -> str:
    """ç¿»è¯‘æ–‡æœ¬ï¼Œä¿ç•™ä»£ç å’Œé“¾æ¥"""
    # ä¿ç•™ä»£ç å—
    if '`' in text:
        parts = []
        in_code = False
        current = []
        code_parts = []

        for char in text:
            if char == '`':
                if in_code:
                    code_parts.append(''.join(current))
                    current = []
                else:
                    parts.append(''.join(current))
                    current = []
                in_code = not in_code
            else:
                current.append(char)

        if current:
            if in_code:
                code_parts.append(''.join(current))
            else:
                parts.append(''.join(current))

        # ç¿»è¯‘éä»£ç éƒ¨åˆ†
        result = []
        code_idx = 0
        for i, part in enumerate(parts):
            if i > 0 and code_idx < len(code_parts):
                result.append('`' + code_parts[code_idx] + '`')
                code_idx += 1
            result.append(translate_simple_text(part))

        return ''.join(result)

    return translate_simple_text(text)


def translate_simple_text(text: str) -> str:
    """ç¿»è¯‘ç®€å•æ–‡æœ¬ï¼ˆæ— ä»£ç å—ï¼‰"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„ç¿»è¯‘é€»è¾‘
    # ç›®å‰å…ˆä¿ç•™åŸæ–‡ï¼Œä»…æ·»åŠ ä¸­æ–‡æ³¨é‡Š

    # å¦‚æœåŒ…å«è‹±æ–‡å¥å­ï¼Œæ·»åŠ ä¸­æ–‡ç¿»è¯‘
    if re.search(r'[A-Za-z]{3,}', text):
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ä¸­è‹±æ–‡æ··åˆ
        if not re.search(r'[\u4e00-\u9fff]', text):
            # çº¯è‹±æ–‡ï¼Œå°è¯•ç¿»è¯‘
            translated = simple_translate(text)
            if translated != text:
                return f"{text}  \n{translated}"

    return text


def simple_translate(text: str) -> str:
    """ç®€å•ç¿»è¯‘ï¼ˆç¤ºä¾‹ï¼‰"""
    # å¸¸è§çŸ­è¯­ç¿»è¯‘
    translations = {
        "Quick Start": "å¿«é€Ÿå¼€å§‹",
        "Usage": "ä½¿ç”¨æ–¹æ³•",
        "Installation": "å®‰è£…",
        "Configuration": "é…ç½®",
        "Examples": "ç¤ºä¾‹",
        "Troubleshooting": "æ•…éšœæ’é™¤",
        "Contributing": "è´¡çŒ®",
        "License": "è®¸å¯è¯",
        "Features": "ç‰¹æ€§",
        "Requirements": "è¦æ±‚",
        "Getting Started": "å…¥é—¨æŒ‡å—",
        "Introduction": "ä»‹ç»",
        "Overview": "æ¦‚è¿°",
        "API Reference": "APIå‚è€ƒ",
        "Documentation": "æ–‡æ¡£",
    }

    for en, zh in translations.items():
        if en.lower() == text.lower():
            return zh

    # æ›¿æ¢å·²çŸ¥æœ¯è¯­
    result = text
    for en, zh in TERM_MAPPING.items():
        result = re.sub(r'\b' + re.escape(en) + r'\b', zh, result, flags=re.IGNORECASE)

    return result


def translate_file(file_path: Path) -> bool:
    """ç¿»è¯‘å•ä¸ªæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        lines = content.split('\n')
        translated_lines = []
        in_code_block = False
        code_fence = ''

        for line in lines:
            # æ£€æµ‹ä»£ç å—
            if line.strip().startswith('```'):
                if not in_code_block:
                    # å¼€å§‹ä»£ç å—
                    in_code_block = True
                    code_fence = line.strip()
                else:
                    # ç»“æŸä»£ç å—
                    in_code_block = False
                    code_fence = ''
                translated_lines.append(line)
                continue

            # åœ¨ä»£ç å—å†…ä¸ç¿»è¯‘
            if in_code_block:
                translated_lines.append(line)
                continue

            # ç¿»è¯‘æ™®é€šè¡Œ
            translated_line = translate_line(line, in_code_block)
            translated_lines.append(translated_line)

        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(translated_lines))

        return True

    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='æ–‡æ¡£æ‰¹é‡ç¿»è¯‘å·¥å…·')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ‰§è¡Œï¼Œä¸è¯¢é—®ç¡®è®¤')
    args = parser.parse_args()

    print("=" * 60)
    print("æ–‡æ¡£æ‰¹é‡ç¿»è¯‘å·¥å…·")
    print("=" * 60)
    print()

    # è·å–å½“å‰ç›®å½•
    root_dir = Path.cwd()

    # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
    print("ğŸ” æ‰«ææ–‡æ¡£æ–‡ä»¶...")
    documents = []
    for ext in ['.md', '.txt', '.rst', '.adoc']:
        documents.extend(root_dir.rglob(f'*{ext}'))

    # è¿‡æ»¤æ’é™¤çš„ç›®å½•
    excluded_dirs = {'.git', 'node_modules', 'venv', '.venv', '__pycache__',
                    '.pytest_cache', 'dist', 'build', '.mypy_cache'}

    filtered_docs = []
    for doc in documents:
        if not any(excluded in doc.parts for excluded in excluded_dirs):
            filtered_docs.append(doc)

    filtered_docs.sort()

    print(f"ğŸ“„ æ‰¾åˆ° {len(filtered_docs)} ä¸ªæ–‡æ¡£æ–‡ä»¶\n")

    if not filtered_docs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£æ–‡ä»¶")
        return

    # ç¡®è®¤ï¼ˆé™¤éä½¿ç”¨--forceï¼‰
    if not args.force:
        print("âš ï¸  è­¦å‘Š: å³å°†ç¿»è¯‘å¹¶æ›¿æ¢æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶")
        print("   å»ºè®®å…ˆåˆ›å»ºgitå¤‡ä»½ï¼")
        try:
            response = input("\næ˜¯å¦ç»§ç»­? [y/N]: ")
            if response.lower() != 'y':
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
                return
        except EOFError:
            print("\nä½¿ç”¨ --force å‚æ•°è‡ªåŠ¨ç¡®è®¤")

    # æ‰§è¡Œç¿»è¯‘
    print(f"\nğŸŒ å¼€å§‹ç¿»è¯‘...\n")

    success_count = 0
    fail_count = 0

    for i, doc in enumerate(filtered_docs, 1):
        rel_path = doc.relative_to(root_dir)
        print(f"[{i}/{len(filtered_docs)}] {rel_path}", end=' ... ')

        if translate_file(doc):
            print("âœ“")
            success_count += 1
        else:
            print("âœ—")
            fail_count += 1

    # æ€»ç»“
    print(f"\n{'='*60}")
    print(f"âœ“ ç¿»è¯‘å®Œæˆ")
    print(f"  æˆåŠŸ: {success_count}")
    print(f"  å¤±è´¥: {fail_count}")
    print(f"  æ€»è®¡: {len(filtered_docs)}")
    print(f"{'='*60}")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
